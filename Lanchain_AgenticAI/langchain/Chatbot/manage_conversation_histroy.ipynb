{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be78c744",
   "metadata": {},
   "source": [
    "### Managing the Coversation History\n",
    "\n",
    "One important concept to understand when building chatbots is how to manage conversation histroy. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "\n",
    "\"trim_messages\" help to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we wnat to always keep the system message and whether to allow partial messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0be47040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pouru\\Desktop\\LangChain\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API\")\n",
    "\n",
    "model = ChatGroq(model=\"openai/gpt-oss-120b\", api_key=groq_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "392168e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is my profession?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='You are an AI engineer.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Which country do I live in?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='You live in India.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, trim_messages, SystemMessage, AIMessage\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=50,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"hello, I'm Pourush Gupta and I am one of the greatest AI engineer from India\"),\n",
    "    AIMessage(content=\"Hello Pourush, How can I help you today?\"),\n",
    "    HumanMessage(content=\"Can you remind me my name?\"),\n",
    "    AIMessage(content=\"Your name is Pourush Gupta.\"),\n",
    "    HumanMessage(content=\"What is my profession?\"),\n",
    "    AIMessage(content=\"You are an AI engineer.\"),\n",
    "    HumanMessage(content=\"Which country do I live in?\"),\n",
    "    AIMessage(content=\"You live in India.\"),\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdb69511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assitant and you need to answer the user query in the {language} language\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ec7412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I don’t have any personal information about you—your name, location, job, or any other details—unless you choose to share them in the conversation. I can only work with the information you provide here, so feel free to let me know what you’d like to discuss or any specifics you’d like me to consider!', additional_kwargs={'reasoning_content': 'The user is asking \"what information do you have?\" They previously asked about profession and country; the assistant guessed \"AI engineer\" and \"India\". This is speculation, not based on any provided data. The user is now asking what information the assistant has. According to policy, we must not fabricate personal data. We must respond that we don\\'t have any personal info about the user. We can ask clarifying question. So respond: I don\\'t have any personal info, I can only respond based on what you share.'}, response_metadata={'token_usage': {'completion_tokens': 180, 'prompt_tokens': 154, 'total_tokens': 334, 'completion_time': 0.376455317, 'completion_tokens_details': {'reasoning_tokens': 105}, 'prompt_time': 0.005899373, 'prompt_tokens_details': None, 'queue_time': 0.052185477, 'total_time': 0.38235469}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_70d048ba3c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--01c56587-7dc6-4c96-8362-783d94d66c5a-0', usage_metadata={'input_tokens': 154, 'output_tokens': 180, 'total_tokens': 334, 'output_token_details': {'reasoning': 105}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer) | prompt | model\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\":messages + [HumanMessage(content=\"what information do you have?\")],\n",
    "        \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc7ebd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
