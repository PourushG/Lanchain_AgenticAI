{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bda5d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ebbddc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pouru\\Desktop\\LangChain\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002BF8F3D2050>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002BF8F529C50>, model_name='openai/gpt-oss-120b', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"openai/gpt-oss-120b\", groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da69ea74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello, Pourush! It’s great to meet you. How can I assist you today?', additional_kwargs={'reasoning_content': 'The user says \"hi my name is pourush gupta, one of the greatest AI engineer\". Probably a greeting. Should respond politely, maybe ask how can I help. No disallowed content. So respond friendly.'}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 86, 'total_tokens': 159, 'completion_time': 0.156121441, 'completion_tokens_details': {'reasoning_tokens': 45}, 'prompt_time': 0.00323226, 'prompt_tokens_details': None, 'queue_time': 0.05277505, 'total_time': 0.159353701}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_df42644058', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--90883f1b-da2f-41dc-9566-dfd0a9b931a4-0', usage_metadata={'input_tokens': 86, 'output_tokens': 73, 'total_tokens': 159, 'output_token_details': {'reasoning': 45}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"hi my name is pourush gupta, one of the greatest AI engineer\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c53355c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='We’ve just started our conversation. Here’s a quick recap:\\n\\n1. **You introduced yourself** – you said your name is **Pourush Gupta** and described yourself as “one of the greatest AI engineers.”  \\n2. **I responded** by greeting you, acknowledging the bold claim, and expressing interest in hearing about your work and achievements.  \\n3. **I asked a follow‑up question** to keep the dialogue going:  \\n   *What inspired you to become an AI engineer, and which areas of AI are you most passionate about?*  \\n\\nSo far we’ve just exchanged introductions and I’m waiting to hear more about your background, projects, and interests in AI. Let me know what you’d like to talk about next!', additional_kwargs={'reasoning_content': 'The user asks \"What we were talking about?\" They want a recap. The assistant should summarize the prior conversation: user introduced themselves as Pourush Gupta, one of the greatest AI engineer. Assistant responded with greeting and asked about inspiration and passions. So the recap is that. Provide a brief summary.'}, response_metadata={'token_usage': {'completion_tokens': 220, 'prompt_tokens': 206, 'total_tokens': 426, 'completion_time': 0.474071055, 'completion_tokens_details': {'reasoning_tokens': 61}, 'prompt_time': 0.00788543, 'prompt_tokens_details': None, 'queue_time': 0.04909751, 'total_time': 0.481956485}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_a28df4bce5', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--e21957c9-7d28-4cbf-9418-f661d37442fc-0', usage_metadata={'input_tokens': 206, 'output_tokens': 220, 'total_tokens': 426, 'output_token_details': {'reasoning': 61}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"hi my name is pourush gupta, one of the greatest AI engineer\"),\n",
    "        AIMessage(content=\"Nice to meet you, Pourush Gupta, one of the greatest AI engineers. That's quite a bold statement, but I'm excited to learn more about your accomplishments and experiences in the field of Artificial Intelligence.\\n\\nAs a conversational AI, I'm designed to be a knowledge hub, and I'd love to engage in a conversation with you about the latest advancements in AI, your projects, or even your thoughts on the future of AI.\\n\\nWhat inspired you to become an AI engineer, and what specific areas of AI are you most passionate about?\"),\n",
    "        HumanMessage(content=\"What we were talking about?\")\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30df5cf1",
   "metadata": {},
   "source": [
    "### Message History\n",
    "\n",
    "We can use a message history class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then laod those messages and pss them into the chain as part fo the input. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "013f1a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84817818",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is pourush gupta, one of the greatest AI engineer\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7ef778f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Pourush! It’s great to meet you. How can I assist you today?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8d9fc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Pourush Gupta.\n"
     ]
    }
   ],
   "source": [
    "config2 = {\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config2\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3821b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"\\u202f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dae949a",
   "metadata": {},
   "source": [
    "### Prompt Templates\n",
    "\n",
    "Prompt templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, whihc are we passing to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0de6035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer all the question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2688c35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Pourush! It’s great to meet you. How can I assist you today?', additional_kwargs={'reasoning_content': 'User says hi, introduces themselves. Likely wants a response. Should greet and respond politely. No disallowed content. So just greet back.'}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 107, 'total_tokens': 164, 'completion_time': 0.142845627, 'completion_tokens_details': {'reasoning_tokens': 30}, 'prompt_time': 0.004004607, 'prompt_tokens_details': None, 'queue_time': 0.054485613, 'total_time': 0.146850234}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_70d048ba3c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--1416d777-8400-4a3a-9dd7-04e9c906085d-0', usage_metadata={'input_tokens': 107, 'output_tokens': 57, 'total_tokens': 164, 'output_token_details': {'reasoning': 30}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"hi my name is Pourush gupta and I am one of the greatest AI engineer\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3d5d33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
