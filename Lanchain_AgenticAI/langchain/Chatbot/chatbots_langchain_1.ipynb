{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda5d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ebbddc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pouru\\Desktop\\LangChain\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000021C8BCE9C90>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000021C8BE41710>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\", groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da69ea74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Pourush Gupta.  I've come across numerous accomplished AI engineers, but I'm excited to learn more about your work and achievements. Your claim to be one of the greatest AI engineers sparks curiosity - what specific areas of AI have you made significant contributions to?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 50, 'total_tokens': 108, 'completion_time': 0.115813904, 'completion_tokens_details': None, 'prompt_time': 0.002436691, 'prompt_tokens_details': None, 'queue_time': 0.051861109, 'total_time': 0.118250595}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--b7fceec4-b85c-4c38-9015-7d2efb3d030d-0', usage_metadata={'input_tokens': 50, 'output_tokens': 58, 'total_tokens': 108})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"hi my name is pourush gupta, one of the greatest AI engineer\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c53355c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"We were just starting our conversation. You introduced yourself as Pourush Gupta, one of the greatest AI engineers, and I responded by welcoming you and expressing interest in learning more about your experiences and accomplishments in the field of Artificial Intelligence. We hadn't discussed any specific topic yet, so we're starting fresh. What would you like to talk about?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 175, 'total_tokens': 245, 'completion_time': 0.10994262, 'completion_tokens_details': None, 'prompt_time': 0.010151072, 'prompt_tokens_details': None, 'queue_time': 0.051930987, 'total_time': 0.120093692}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--597bbffe-e2de-4431-b31f-ce763611dc09-0', usage_metadata={'input_tokens': 175, 'output_tokens': 70, 'total_tokens': 245})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"hi my name is pourush gupta, one of the greatest AI engineer\"),\n",
    "        AIMessage(content=\"Nice to meet you, Pourush Gupta, one of the greatest AI engineers. That's quite a bold statement, but I'm excited to learn more about your accomplishments and experiences in the field of Artificial Intelligence.\\n\\nAs a conversational AI, I'm designed to be a knowledge hub, and I'd love to engage in a conversation with you about the latest advancements in AI, your projects, or even your thoughts on the future of AI.\\n\\nWhat inspired you to become an AI engineer, and what specific areas of AI are you most passionate about?\"),\n",
    "        HumanMessage(content=\"What we were talking about?\")\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30df5cf1",
   "metadata": {},
   "source": [
    "### Message History\n",
    "\n",
    "We can use a message history class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore. Future interactions will then laod those messages and pss them into the chain as part fo the input. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f1a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_histor(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
