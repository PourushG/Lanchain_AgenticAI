{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be6b6aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API\")\n",
    "\n",
    "model = ChatGroq(model = \"openai/gpt-oss-120b\", api_key = groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abfe4e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "session_store = {}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in session_store:\n",
    "        session_store[session_id] = ChatMessageHistory()\n",
    "    return session_store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9190bcb6",
   "metadata": {},
   "source": [
    "### Prompt Templates\n",
    "\n",
    "Prompt templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, whihc are we passing to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "882b0a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello Pourush! üëã It‚Äôs great to meet an AI engineer‚Äîespecially one who‚Äôs proud of their work. How can I assist you today? Whether you‚Äôve got a technical question, need help brainstorming a project, or just want to chat about the latest trends in AI, I‚Äôm here to help!', additional_kwargs={'reasoning_content': 'We need to respond as ChatGPT. The user says \"hi my name is Pourush gupta and I am one of the greatest AI engineer\". Likely they are introducing themselves. We can respond politely, ask how we can help, maybe compliment. Should be friendly.'}, response_metadata={'token_usage': {'completion_tokens': 128, 'prompt_tokens': 107, 'total_tokens': 235, 'completion_time': 0.29659896, 'completion_tokens_details': {'reasoning_tokens': 56}, 'prompt_time': 0.004245186, 'prompt_tokens_details': None, 'queue_time': 0.047835224, 'total_time': 0.300844146}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_1d1727abc9', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--c53d6417-062c-481e-aab0-1cb30df8eb1c-0', usage_metadata={'input_tokens': 107, 'output_tokens': 128, 'total_tokens': 235, 'output_token_details': {'reasoning': 56}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are helpful assistant. Answer all the question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|model\n",
    "chain.invoke({\"messages\":[HumanMessage(content=\"hi my name is Pourush gupta and I am one of the greates AI engineer\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd8bd3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Pourush! Great to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"hi this side Pourush Gupta, one of the greates AI engineer\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d453d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§™‡•Ç‡§∞‡•Å‡§∑ ‡§ó‡•Å‡§™‡•ç‡§§‡§æ! ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à‡•§ ‡§Ø‡§π ‡§∏‡•Å‡§®‡§ï‡§∞ ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•Å‡§à ‡§ï‡§ø ‡§Ü‡§™ ‡§è‡§ï ‡§Æ‡§π‡§æ‡§® AI ‡§á‡§Ç‡§ú‡•Ä‡§®‡§ø‡§Ø‡§∞ ‡§π‡•à‡§Ç‡•§ ‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§ï‡§ø‡§∏‡•Ä ‡§™‡•ç‡§∞‡•ã‡§ú‡•á‡§ï‡•ç‡§ü, ‡§§‡§ï‡§®‡•Ä‡§ï‡•Ä ‡§∏‡§µ‡§æ‡§≤, ‡§Ø‡§æ ‡§ï‡§ø‡§∏‡•Ä ‡§≠‡•Ä ‡§§‡§∞‡§π ‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ö‡§æ‡§π‡§ø‡§è, ‡§§‡•ã ‡§¨‡•á‡§ù‡§ø‡§ù‡§ï ‡§¨‡§§‡§æ‡§á‡§è‚Äî‡§Æ‡•à‡§Ç ‡§Ø‡§π‡§æ‡§Å ‡§Æ‡§¶‡§¶ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡•Ç‡§Å! üöÄ\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Answer the user query in {language} language\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt|model\n",
    "\n",
    "response = chain.invoke({\"messages\":[HumanMessage(content=\"hi my name is Pourush Gupta and I am one of the greatest AI engineer\")], \"language\":\"hindi\"})\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61435fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§™‡•Ç‡§∞‡•Å‡§∑ ‡§ó‡•Å‡§™‡•ç‡§§‡§æ! ‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à‡•§ ‡§Ü‡§™ ‡§è‡§ï ‡§Æ‡§π‡§æ‡§® AI ‡§á‡§Ç‡§ú‡•Ä‡§®‡§ø‡§Ø‡§∞ ‡§π‡•à‡§Ç‚Äî‡§Ø‡§π ‡§∏‡•Å‡§®‡§ï‡§∞ ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•Å‡§à‡•§ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•à‡§∏‡•á ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å? ‡§Ø‡§¶‡§ø ‡§ï‡•ã‡§à ‡§∏‡§µ‡§æ‡§≤ ‡§π‡•à ‡§Ø‡§æ ‡§ï‡§ø‡§∏‡•Ä ‡§™‡•ç‡§∞‡•ã‡§ú‡•á‡§ï‡•ç‡§ü ‡§Æ‡•á‡§Ç ‡§∏‡§π‡§æ‡§Ø‡§§‡§æ ‡§ö‡§æ‡§π‡§ø‡§è, ‡§§‡•ã ‡§¨‡•á‡§ù‡§ø‡§ù‡§ï ‡§¨‡§§‡§æ‡§á‡§è‡•§\n"
     ]
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history, input_messages_key=\"messages\")\n",
    "config = {\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"hi my name is Pourush Gupta and I am of the greates AI engineer\")],\"language\":\"hindi\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
