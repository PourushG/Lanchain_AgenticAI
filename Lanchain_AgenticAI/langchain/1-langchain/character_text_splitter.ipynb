{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b88c35e8",
   "metadata": {},
   "source": [
    "## How to split by character-character text splitter\n",
    "\n",
    "This is the simplest method. This splits based on a given character sequence, which defaults to \"\\n\\n\". Chunk length is measured by number of characters.\n",
    "\n",
    "How the text is spoit: by single character seperator\n",
    "how the chunk size is measured: by number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba271b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'example.txt'}, page_content='Not my story: \\n\\nI worked for a while for a (now defunct) search engine company whose middleware had been written \\nby an insane person (about 5000 Java source files) who had moved on. Some of the characteristics:\\n\\nMost methods began with for(;;) so that continue statements could be used as gotos\\n\\nAlmost all methods returned an object which wrapped an int, a string, a boolean and an object array, \\nso the return type could be changed later (and woe be unto any code using the return value).\\n\\nClasses and packages all had random names - I mean, literally, \\nthe author kept a huge printout of random unique strings in his desk and crossed one off every time he had to create \\na package or class\\n\\nShutdown was accomplished by killing threads in a loop repeatedly until they were all dead - \\nlike if the way you shut off your car was to open the hood and hit things with a hammer until the engine stopped\\n\\nAll thrown runtime errors were logged as more unique random strings - to diagnose, you grepped the source code\\n\\nEvery assignment was immediately followed by a test that the value had actually been assigned\\n\\nThis company had a new CEO who wanted to sell this stuff to other industries than their one customer, a three-letter agency\\nof the US government, and I was hired to replace this stuff with something reliable. However, they made all their money on \\n\"consultants\" who sat in basements in Virginia babysitting the thing and fixing things with hex editors when it corrupted\\nits own data, which was a few times daily. The software being embarrassingly broken *was* their cash cow. And I learned that\\nthis was not unusual.\\n\\nSo I do not wonder why Snowden had access to what he had access to, or why the first version of the Obamacare web site was a\\ndisaster, or why Hillary might not have wanted to use a mail system run by contractors such as this. This is the state of\\ngovernment IT.\\n\\nsrc: https://www.quora.com/What-is-the-most-absurd-code-youve-ever-seen')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader('example.txt')\n",
    "data = loader.load()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3445852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 195, which is longer than the specified 100\n",
      "Created a chunk of size 194, which is longer than the specified 100\n",
      "Created a chunk of size 200, which is longer than the specified 100\n",
      "Created a chunk of size 206, which is longer than the specified 100\n",
      "Created a chunk of size 110, which is longer than the specified 100\n",
      "Created a chunk of size 516, which is longer than the specified 100\n",
      "Created a chunk of size 261, which is longer than the specified 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'example.txt'}, page_content='Not my story:'),\n",
       " Document(metadata={'source': 'example.txt'}, page_content='I worked for a while for a (now defunct) search engine company whose middleware had been written \\nby an insane person (about 5000 Java source files) who had moved on. Some of the characteristics:'),\n",
       " Document(metadata={'source': 'example.txt'}, page_content='Most methods began with for(;;) so that continue statements could be used as gotos'),\n",
       " Document(metadata={'source': 'example.txt'}, page_content='Almost all methods returned an object which wrapped an int, a string, a boolean and an object array, \\nso the return type could be changed later (and woe be unto any code using the return value).'),\n",
       " Document(metadata={'source': 'example.txt'}, page_content='Classes and packages all had random names - I mean, literally, \\nthe author kept a huge printout of random unique strings in his desk and crossed one off every time he had to create \\na package or class'),\n",
       " Document(metadata={'source': 'example.txt'}, page_content='Shutdown was accomplished by killing threads in a loop repeatedly until they were all dead - \\nlike if the way you shut off your car was to open the hood and hit things with a hammer until the engine stopped'),\n",
       " Document(metadata={'source': 'example.txt'}, page_content='All thrown runtime errors were logged as more unique random strings - to diagnose, you grepped the source code'),\n",
       " Document(metadata={'source': 'example.txt'}, page_content='Every assignment was immediately followed by a test that the value had actually been assigned'),\n",
       " Document(metadata={'source': 'example.txt'}, page_content='This company had a new CEO who wanted to sell this stuff to other industries than their one customer, a three-letter agency\\nof the US government, and I was hired to replace this stuff with something reliable. However, they made all their money on \\n\"consultants\" who sat in basements in Virginia babysitting the thing and fixing things with hex editors when it corrupted\\nits own data, which was a few times daily. The software being embarrassingly broken *was* their cash cow. And I learned that\\nthis was not unusual.'),\n",
       " Document(metadata={'source': 'example.txt'}, page_content='So I do not wonder why Snowden had access to what he had access to, or why the first version of the Obamacare web site was a\\ndisaster, or why Hillary might not have wanted to use a mail system run by contractors such as this. This is the state of\\ngovernment IT.'),\n",
       " Document(metadata={'source': 'example.txt'}, page_content='src: https://www.quora.com/What-is-the-most-absurd-code-youve-ever-seen')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size = 100, chunk_overlap = 20)\n",
    "text_splitter.split_documents(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3f1de0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 195, which is longer than the specified 100\n",
      "Created a chunk of size 194, which is longer than the specified 100\n",
      "Created a chunk of size 200, which is longer than the specified 100\n",
      "Created a chunk of size 206, which is longer than the specified 100\n",
      "Created a chunk of size 110, which is longer than the specified 100\n",
      "Created a chunk of size 516, which is longer than the specified 100\n",
      "Created a chunk of size 261, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Not my story:'\n",
      "page_content='I worked for a while for a (now defunct) search engine company whose middleware had been written \n",
      "by an insane person (about 5000 Java source files) who had moved on. Some of the characteristics:'\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\n",
    "with open('example.txt') as f:\n",
    "    text = f.read()\n",
    "\n",
    "\n",
    "text_splitter = CharacterTextSplitter(separator=\"\\n\\n\", chunk_size = 100, chunk_overlap = 20)\n",
    "text_data = text_splitter.create_documents([text])\n",
    "print(text_data[0])\n",
    "print(text_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6baa334e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POURUSH  GUPTA  pourushgupta303@gmail.com\n",
      " \n",
      "|\n",
      " \n",
      "+91-9897461806\n",
      "  \n",
      "|\n",
      " Github |  L \n",
      "I N K D I N \n",
      " |  L \n",
      "E E T C O D E \n",
      "  \n",
      "Skills \n",
      " \n",
      "Technical  :  Professional  working  proficiency:  C++  |  Python  |  Machine  Learning  Algorithms  |  LLMs  |  RAGs  |  GANs  |  CNNs  |  LLM  fine-Tuning  |  Transfer  Learning  |  Data  Visualization  |  \n",
      "AI\n",
      " \n",
      "Agents\n",
      " \n",
      "|\n",
      " \n",
      "Linear\n",
      " \n",
      "Algebra\n",
      " \n",
      "|\n",
      " \n",
      "Image\n",
      " \n",
      "Preprocessing\n",
      " \n",
      "|\n",
      " \n",
      "Langchain\n",
      " \n",
      "|\n",
      " \n",
      "LangGraph\n",
      " \n",
      "|\n",
      " \n",
      "LoRA\n",
      " \n",
      "|\n",
      " \n",
      "QLoRA\n",
      " Limited  working  proficiency:  NLP  |   MySQL  |  Statistics  |  Microsoft  Excel  |  Web  Development  |  Computer  Vision  |  Exploratory  Data  Analysis  |  CVAT  Non-Technical  :  Critical  Thinking  |  Outstanding  Communication  |  Problem  Solving  |  Teamwork  |  Adaptability  |  Creative  Thinking  |  Researching  \n",
      "Experience Datopic  Technologies  |  Associate  Software  Engineer   |  Onsite:  Mohali,  Punjab                                         Feb’25  -  Present  ●  Architected  end ‑ to ‑ end  GPU ‑ accelerated  PEFT  pipelines  using  LoRA  &  QLoRA  with  seamless  instruction  tuning,  driving  a  60%  \n",
      "reduction\n",
      " \n",
      "in\n",
      " \n",
      "memory\n",
      " \n",
      "footprint\n",
      " \n",
      "and\n",
      " \n",
      "50%\n",
      " \n",
      "faster\n",
      " \n",
      "adaptation\n",
      " \n",
      "while\n",
      " \n",
      "preserving\n",
      " \n",
      "≥ 95%\n",
      " \n",
      "of\n",
      " \n",
      "model\n",
      " \n",
      "accuracy\n",
      ".\n",
      " ●  Built  AI  governance  &  alignment  frameworks  with  real ‑ time  query  classification  at  95%  accuracy ,  slashing  unsafe  or  \n",
      "non\n",
      "‑\n",
      "compliant\n",
      " \n",
      "outputs\n",
      " \n",
      "by\n",
      " \n",
      "90%\n",
      " \n",
      "and\n",
      " \n",
      "ensuring\n",
      " \n",
      "robust\n",
      " \n",
      "policy\n",
      " \n",
      "adherence.\n",
      " ●  Integrated  RAG ‑ powered  knowledge  retrieval  via  Pinecone,  Chroma  &  FAISS,  elevating  response  relevance  by  80%  and  \n",
      "introducing\n",
      " \n",
      "a\n",
      " \n",
      "cross-domain\n",
      " \n",
      "fusion\n",
      " \n",
      "strategy\n",
      " \n",
      "to\n",
      " \n",
      "cut\n",
      " \n",
      "training\n",
      " \n",
      "time\n",
      " \n",
      "by\n",
      " \n",
      "80%\n",
      " \n",
      "and\n",
      " \n",
      "computational\n",
      " \n",
      "costs\n",
      " \n",
      "by\n",
      " \n",
      "85%\n",
      ".\n",
      " ●  Engineered  CPU ‑ native,  in ‑ memory  LLM  microservices  for  edge ‑ ready,  low ‑ latency  inference,  eliminating  GPU  dependencies,  \n",
      "reducing\n",
      " \n",
      "infrastructure\n",
      " \n",
      "costs\n",
      " \n",
      "by\n",
      " \n",
      "70%\n",
      ",\n",
      " \n",
      "and\n",
      " \n",
      "doubling\n",
      " \n",
      "data\n",
      "‑\n",
      "relationship\n",
      " \n",
      "extraction\n",
      " \n",
      "throughput.\n",
      "  SETV  Global  |  AI/ML  Engineer  Intern  |  Remote                                Nov’24  -  Jan’25  ●  Achieved  93%  mAP  across  cervical,  ovarian,  and  breast  cancer  detection,  improving  accuracy  by  30%  and  reducing  false  \n",
      "positives\n",
      " \n",
      "by\n",
      " \n",
      "25%\n",
      " \n",
      "through\n",
      " \n",
      "optimized\n",
      " \n",
      "YOLOv8\n",
      " \n",
      "&\n",
      " \n",
      "EfficientNet\n",
      " \n",
      "models\n",
      " \n",
      "with\n",
      " \n",
      "advanced\n",
      " \n",
      "preprocessing\n",
      " \n",
      "and\n",
      " \n",
      "segmentation.\n",
      " ●  Integrated  AI  diagnostics  into  clinical  workflows,  cutting  analysis  time  by  50%  and  boosting  patient  screening  capacity  by  \n",
      "40%\n",
      ",\n",
      " \n",
      "empowering\n",
      " \n",
      "teams\n",
      " \n",
      "with\n",
      " \n",
      "real\n",
      "‑\n",
      "time,\n",
      " \n",
      "scalable\n",
      " \n",
      "cancer\n",
      "‑\n",
      "detection\n",
      " \n",
      "tools.\n",
      "  Techdice  IT  Solutions  |  AI/ML  Developer  Intern  |  Remote               May’24  -  Aug’24  ●  Boosted  social  media  posting  efficiency  by  70%  and  cut  manual  workflow  time  by  80%  by  architecting  an  Appium/Selenium  \n",
      "automation\n",
      " \n",
      "framework\n",
      " \n",
      "for\n",
      " \n",
      "multi\n",
      "‑\n",
      "image\n",
      " \n",
      "posting,\n",
      " \n",
      "dynamic\n",
      " \n",
      "captioning,\n",
      " \n",
      "and\n",
      " \n",
      "automated\n",
      " \n",
      "Instagram\n",
      " \n",
      "logins.\n",
      " ●  Increased  content  engagement  by  50%  and  accelerated  video  production  3×  by  developing  a  text ‑ to ‑ video  ML  model,  reducing  \n",
      "turnaround\n",
      " \n",
      "from\n",
      " \n",
      "hours\n",
      " \n",
      "to\n",
      " \n",
      "minutes.\n",
      " \n",
      "Projects  SOIL  IMAGE  CLASSIFICATION  FOR  PULSES  CULTIVATION,  G i t h u b                                                 Nov’23  ●  Designed  and  implemented  an  image  analysis  system  integrating  pre-processing  techniques  and  GLCM  feature  extraction  for  soil  type  \n",
      "classification.\n",
      " \n",
      "achieved\n",
      " \n",
      "a\n",
      " \n",
      "97%\n",
      " \n",
      "accuracy\n",
      " \n",
      "rate\n",
      " \n",
      "by\n",
      " \n",
      "training\n",
      " \n",
      "a\n",
      " \n",
      "deep\n",
      " \n",
      "learning\n",
      " \n",
      "neural\n",
      " \n",
      "network\n",
      " \n",
      "model.\n",
      " \n",
      "Facilitated\n",
      " \n",
      "farmers'\n",
      " \n",
      "selection\n",
      " \n",
      "of\n",
      " \n",
      "optimal\n",
      " \n",
      "soil\n",
      " \n",
      "for\n",
      " \n",
      "pulse\n",
      " \n",
      "cultivation,\n",
      " \n",
      "resulting\n",
      " \n",
      "in\n",
      " \n",
      "enhanced\n",
      " \n",
      "yields.\n",
      " ●  Technologies  used:  Python  Tkinter,  Convolutional  Neural  Network  (CNN) ,  GLCM,  OpenCV,  Transfer  Learning  RADHYSHAYM:  PERSONAL  DESKTOP  ASSISTANT,   G i t h u b                              Dec’22  ●  Developed  a  Python  desktop  assistant  utilising  OpenAI  APIs.  Implemented  voice-activated  features  for  tasks  including  music  \n",
      "playback,\n",
      " \n",
      "photography,\n",
      " \n",
      "code\n",
      " \n",
      "generation,\n",
      " \n",
      "web\n",
      " \n",
      "browsing,\n",
      " \n",
      "weather\n",
      " \n",
      "updates,\n",
      " \n",
      "news,\n",
      " \n",
      "and\n",
      " \n",
      "basic\n",
      " \n",
      "chat\n",
      " \n",
      "interactions.\n",
      " ●  Technologies  used:  OpenAI  APIs  and  Python.   PREDICTWISE:  INTELLIGENT  STOCK  PRICE  STABILITY  PREDICTION,   G i t h u b                                                             Oct’22  ●  Created  and  deployed  a  machine  learning  model  for  stock  stability  classification,  leveraging  research-driven  feature  selection  and  data  \n",
      "preprocessing.\n",
      " \n",
      "Evaluated\n",
      " \n",
      "various\n",
      " \n",
      "algorithms\n",
      " \n",
      "for\n",
      " \n",
      "optimal\n",
      " \n",
      "performance\n",
      " \n",
      "and\n",
      " \n",
      "deployed\n",
      " \n",
      "the\n",
      " \n",
      "selected\n",
      " \n",
      "model\n",
      " \n",
      "through\n",
      " \n",
      "Streamlit\n",
      " \n",
      "for\n",
      " \n",
      "real-time\n",
      " \n",
      "predictions.\n",
      " ●  Technologies  used:  machine  learning  algorithms ,  Pandas,  Numpy,  Matplotlib,  Streamlit,  Seaborn,  and  Sklearn.  \n",
      "Education ●  BTech  -  CSE  (Specialization  in  Artificial  Intelligence,  Machine  Learning,  and  Deep  Learning)                                              2021-25       CGPA:  8.03/10  (overall  till  7th  sem)\n",
      " \n",
      "     Teerthanker  Mahaveer  University,  India\n",
      "  \n",
      " \n",
      "                                 \n",
      "Awards/Achievements  \n",
      "  \n",
      "●  Smart  India  Hackathon  (SIH)  2024  -  Grand  Finalist                                  Dec’24  ●  Earned  a  Silver  4-star  badge  in  C++  programming  on  HackerRank .                                           July’24  ●  Solved  400+  problems  on  Leetcode .                          July’24  ●  Achieved  a  top  30  ranking  out  of  261  speakers  university-wide  in  the  Speech  Master’s  Competition.                    Mar’24  ●  Earned  an  NPTEL  Machine  Learning  certificate  from  IIIT,  awarded  to  just  40  out  of  9,000+  participants  nationwide             Oct’23\n",
      "Roles  and  responsibilities  \n",
      "  \n",
      "●  Event  Coordinator  at  the  TMU  TEDx  team.                           Mar’  24  -  Jun’  25  ●  Founding  Member  and  Mentor  at  SpeechMaster’s  Club.                                                  Mar’  24  -  Jun’  25  ●  Volunteer  with  the  TMU  NSS  team.                                                        Nov’  23  -  Jun’  25  ●  Event  coordinator  at  Parivartan  NGO.                            April’  22  -  Present\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"/home/dtp202505-u05/Desktop/langchain_agenticAI/langchain/1-langchain/MYresume.pdf\")\n",
    "data = loader.load()\n",
    "for d in data:\n",
    "    print(d.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
