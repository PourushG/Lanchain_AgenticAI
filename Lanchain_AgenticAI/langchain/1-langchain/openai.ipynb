{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a828f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") #langsmith tracking\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "638799f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtp202505-u05/Desktop/langchain_agenticAI/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'content' from 'langchain_core.messages' (/home/dtp202505-u05/Desktop/langchain_agenticAI/venv/lib/python3.11/site-packages/langchain_core/messages/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      2\u001b[39m llm = ChatOpenAI() \u001b[38;5;66;03m# default model is gpt-3.5-turbo\u001b[39;00m\n\u001b[32m      3\u001b[39m llm_gpt_4 = ChatOpenAI(model_name=\u001b[33m\"\u001b[39m\u001b[33mgpt-4\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain_agenticAI/venv/lib/python3.11/site-packages/langchain_openai/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Module for OpenAI integrations.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI, ChatOpenAI\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAIEmbeddings, OpenAIEmbeddings\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAI, OpenAI\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain_agenticAI/venv/lib/python3.11/site-packages/langchain_openai/chat_models/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Module for OpenAI chat models.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mazure\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      6\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mAzureChatOpenAI\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatOpenAI\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain_agenticAI/venv/lib/python3.11/site-packages/langchain_openai/chat_models/azure.py:20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field, SecretStr, model_validator\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Self\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseChatOpenAI\n\u001b[32m     22\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     25\u001b[39m _BM = TypeVar(\u001b[33m\"\u001b[39m\u001b[33m_BM\u001b[39m\u001b[33m\"\u001b[39m, bound=BaseModel)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/langchain_agenticAI/venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:67\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguage_models\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     45\u001b[39m     BaseChatModel,\n\u001b[32m     46\u001b[39m     LangSmithParams,\n\u001b[32m     47\u001b[39m )\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     49\u001b[39m     AIMessage,\n\u001b[32m     50\u001b[39m     AIMessageChunk,\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m     is_data_content_block,\n\u001b[32m     66\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m content \u001b[38;5;28;01mas\u001b[39;00m types\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     69\u001b[39m     InputTokenDetails,\n\u001b[32m     70\u001b[39m     OutputTokenDetails,\n\u001b[32m     71\u001b[39m     UsageMetadata,\n\u001b[32m     72\u001b[39m )\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mblock_translators\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     74\u001b[39m     _convert_from_v03_ai_message,\n\u001b[32m     75\u001b[39m     convert_to_openai_data_block,\n\u001b[32m     76\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'content' from 'langchain_core.messages' (/home/dtp202505-u05/Desktop/langchain_agenticAI/venv/lib/python3.11/site-packages/langchain_core/messages/__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI() # default model is gpt-3.5-turbo\n",
    "llm_gpt_4 = ChatOpenAI(model_name=\"gpt-4\")\n",
    "print(llm)\n",
    "llm_gpt_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5b69e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Transformers are electrical devices that are used to transfer electrical energy between two or more circuits through electromagnetic induction. They are used to increase or decrease the voltage of an alternating current (AC) while keeping the frequency the same. Transformers consist of two coils of wire (known as windings) that are magnetically coupled, with one coil connected to a source of power and the other to a load. By varying the number of turns in each coil, transformers can step-up (increase) or step-down (decrease) the voltage of the electrical energy being transferred. Transformers are commonly used in power distribution systems, electrical appliances, and electronic devices to efficiently transfer electrical energy across different voltage levels.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 137, 'prompt_tokens': 11, 'total_tokens': 148, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CahmEFUGgJ4PSZuqoaRSZnZjU1Lrk', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--32fc7f86-ce85-4109-948b-942ffca98dd8-0' usage_metadata={'input_tokens': 11, 'output_tokens': 137, 'total_tokens': 148, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"What are transformers?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7967b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"You are a helpful ai assistant and you need to asnwer the user's questions accurately.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a helpful ai assistant and you need to asnwer the user's questions accurately.\"),\n",
    "    (\"user\",\"{input}\")\n",
    "])\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "146976c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Transformers are a type of model architecture used in machine learning, particularly in the field of natural language processing (NLP). They were introduced in a paper called \"Attention is All You Need\" by Vaswani et al., 2017.\\n\\nThe key innovation of transformers is the self-attention mechanism, which calculates the relevance of each input component in relation to all other parts for better context understanding. This structure allows for more parallelizable computation and can handle longer sequences better than recurrent models like LSTM (Long Short Term Memory) and GRU (Gated Recurrent Unit), making it a superior model for many NLP tasks.\\n\\nTransformers are widely used in modern NLP models like Google\\'s BERT, OpenAI\\'s GPT-2/3, and others for tasks like translation, text summarization, sentiment analysis, and more.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 170, 'prompt_tokens': 36, 'total_tokens': 206, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'id': 'chatcmpl-CaynoHG3iPLOWdSfq2PGlb6mfBlE0', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--ce2a13e7-76b9-45ee-8d33-d1f7c859cfbb-0' usage_metadata={'input_tokens': 36, 'output_tokens': 170, 'total_tokens': 206, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt|llm_gpt_4\n",
    "\n",
    "response = chain.invoke({\"input\":\"what are transformers in machine learning?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f83512",
   "metadata": {},
   "source": [
    "Output parsers are used to provide the clean output from the raw output generated by the LLM. There are various in-built output parsers present in the langchain_core, you can access them based on your needs: https://reference.langchain.com/python/langchain_core/output_parsers/. Also, langchain_core provides to ease to create a custom output parsers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c9fac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly. Transformers are a type of model architecture used in machine learning, particularly in the field of natural language processing (NLP). Transformers were introduced in the paper titled “Attention is All You Need,” by Vaswani et al., back in 2017.\n",
      "\n",
      "The main innovation of Transformer models is the use of the \"attention mechanism\", which essentially allows the model to focus on different parts of the input sequentially, accumulating more valuable information from the input data.\n",
      "\n",
      "Here are some key components and features of the Transformer architecture:\n",
      "\n",
      "1. Self-Attention: Also known as scaled dot-product attention, it allows the model to weigh the importance of words in the input sequence. This helps the model to better understand the context and semantics of input data.\n",
      "\n",
      "2. Positional Encoding: Transformer models do not inherently recognize the order of data. So, to help the model understand sequence in the data, positional encoding is added to the input layer. This way, the model can distinguish between words that come early and those that come later in the sequence.\n",
      "\n",
      "3. Layer Stacking: In Transformer architecture, multiple identical layers are stacked, creating deep learning models. Each of these layers learn different features about the input, thereby enhancing the learning efficiency of the model.\n",
      "\n",
      "4. Encoder-Decoder Architecture: The transformers usually consists of two main parts: the Encoder which reads and processes the input data, and the Decoder which generates the output.\n",
      "\n",
      "5. Parallelization: Unlike the previous architectures such as RNNs and LSTM, Transformers allow the parallelization of the whole sequence, which leads to faster training times.\n",
      "\n",
      "Transformers are behind today's leading NLP models, like BERT, GPT-3, and others. They are widely used in machine translation, text summarization, and as a component in recommendation systems.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt|llm_gpt_4|output_parser\n",
    "response = chain.invoke({\"input\":\"can you explain are transformers in machine learning\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb5b588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
